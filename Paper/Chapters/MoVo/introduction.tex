\section{Introduction}

\subsection{The Popularity of Voice Authentication on Smartphones}

According to reports issued by several market research firms, the total number of smartphone users worldwide is over 3 billion this year and is expected to reach 3.9 billion by 2023~\cite{report2018newzoo,report2019forrester}. The rapidly increasing use of smartphones is actuating the need for better protection. User authentication on smartphones has thus been an important area of research. 

Survey papers~\cite{vongsingthong2014survey,mahfouz2017survey,shankar2018survey} have compared the strengths and limitations of existing authentication methods, from knowledge-based methods such as PIN or password to identity-based methods such as fingerprint and face.
%
PIN and password are the most widely used authentication methods. However, when the users have wet or dirty fingers or wear gloves on their hands, such touchscreen-related authentication methods will not work. The fingerprint authentication system suffers from the same problem. As for face recognition, it stops working when users are wearing moisturizing mask sheets or other head wearables such as ski goggles. In the aforementioned scenarios, voice authentication provides better convenience to users and thus a great alternative.


In fact, voice authentication has been adopted in a wide variety of smartphone applications. 
For example, Android users can say ``Ok Google'' to access Google assistant directly~\cite{onlinegoogle}; the Tencent company adopts Voiceprint to provide securely, faster and easier log-ins to WeChat accounts, available on both Android and iOS platforms~\cite{onlinewechat}; the BioTrust uses voice biometrics to allow elderly and sick people to order prescription medication without the need to leave the house~\cite{onlinebio}; the Citi bank uses voice biometrics authentication system for phone banking, which reduces the number of tedious security questions~\cite{onlineciti}; the LMH Blockchain adopts Say-Tec~\cite{onlinesaytec} to authenticate, validate, process, and protect users' blockchain assets and cryptocurrency by voice~\cite{onlineblockchain}.
%
Based on a market research report published in 2019~\cite{onlinemarket}, the speech and voice recognition market is expected to grow from 
 \$7.5 billion as in 2018 to  \$21.5 billion by 2024. 
 
 

\subsection{Voice Spoofing Attacks}\label{sec:spoof}
Despite of the increasing trend for the adopting of voice authentication, this method is not unassailable, just like other methods. Researchers have found that voice authentication system are vulnerable to the following four attacks~\cite{wu2015spoofing}: impersonation attack, replay attack, speech synthesis, and voice conversion.
\begin{itemize}
	\item  Impersonation attack refers to the scenario where an attacker tries to mimic the legitimate userâ€™s voice without any computer-aided technology.
	\item Replay attack refers to the scenario where an attacker replays a pre-recorded speech sample collected from the legitimate user. 
	\item Speech synthesis refers to the scenario where an attacker generates intelligible, natural-sounding artificial speech from text.
	\item Voice conversion refers to the scenario where an attacker converts his speech signals to an artificial speech signal which has similar timbre and prosody to that of the legitimate user.
\end{itemize}


Among the four voice spoofing attacks, the impersonation attack is the hardest to perform, as Lau et al.~\cite{lau2005testing} have found that successful impersonation attacks require professional impersonators or attackers whose natural voices already similar to the legitimate user's. Even with professional mimicry artists or linguists, the existing voice authentication system is hard to fool~\cite{mariethoz2005can}.


The other three types of attacks, however, are much easier to be conducted. Because attackers could get the victim's voice recordings. It is common to see people use voice assistants (Alexa, Bixby, Cortana, Google, Siri, etc.) in public and attackers can record the victim's voice on the site or remotely. Moreover, people nowadays not only post text or image to social media sites (Facebook, Twitter, LinkedIn, YouTube, etc.), but also upload videos containing their voices. Attackers can extract the victim's voice from those online videos and build the speech profile of each victim. With a properly built speech profile, attackers are able to use the victim's voice to say just about anything, using algorithms such as vector quantization~\cite{abe1990voice}, probabilistic transform~\cite{stylianou1998continuous}, or neural networks~\cite{desai2009voice}. Such voice generation techniques are well-established. As an evidence, celebrity voice changer websites or apps could generate natural sounding speeches as from Obama, Trump, Stephen Hawking, Bruce Wayne, and many more.




Some may argue that large training data is required to build the victim's speech profile. However, for the purpose of attacking, the attackers may only need to use small training data to generate the hotword or the activation phrase. There is no need to generate every possible sentence. This is because most voice authentication systems adopts a one-time authentication scheme to grant access, instead of a continuous authentication scheme~\cite{feng2017continuous}.

\begin{landscape}
	\begin{figure*}[h]
		\begin{minipage}[t]{0.33\textwidth}
			\fbox{\includegraphics[width=1.2\textwidth]{voicematch}}
			\subcaption{Enabling Voice setting.}
			\label{fig:voicematch}
		\end{minipage}
		\hspace{1in}
		\begin{minipage}[t]{0.33\textwidth}
			\fbox{\includegraphics[width=1.2\textwidth]{voicematch2}}
			\subcaption{Voice Match warning.}
			\label{fig:voicematch2}
		\end{minipage}
		\hspace{1in}
		\begin{minipage}[t]{0.33\textwidth}
			\fbox{\includegraphics[width=1.2\textwidth]{email}}
			\subcaption{Information leakage when the phone is locked. }
			\label{fig:email}
		\end{minipage}  
	\vspace{-.05in}
		\caption{Screenshots about Voice Match on Google Nexus 6P.}\label{fig:example}
	\end{figure*}
\end{landscape}

For example, on a Google Nexus~6P smartphone running Android 8.1.0, it provides the Voice Match feature which allow users to access their personal data by voices\footnote{When the Voice Match feature first came out, Android users could fully unlock the phone with this function. However, starts from January 2019, Google removes the ability for Voice Match to act as a password due to security concerns. The previous ``Unlock with Voice Match'' is replaced to only providing ``personal results''. Such results come from emails, calendar entries, contacts, etc., and are still sensitive information.}. If an attacker replays the victim's ``Ok Google'' utterance, followed by ``show me my emails'' in his own voice (not the victim's), the Android system will regard him as the legitimate user (false acceptance) and show the emails. Because the authentication only check the hotword. Once the access is granted, any command coming after will be executed, no matter in whose voice.


Fig.~\ref{fig:example} are the screenshots when the aforementioned replay attack is tested in reality. Fig.~\ref{fig:voicematch} shows how to enable the Voice Match function. Fig.~\ref{fig:voicematch2} indicates the system is aware of its vulnerability to impersonation attack and replay attack. Fig.~\ref{fig:email} demonstrates the attacker could steal sensitive information without unlocking the phone (the closed padlock at the top). In this test, the leaked information are emails from the Gmail Inbox, which include the credit card information sent from the victim's mom and a secret from his friend. Recall that to conduct this attack successfully, all the thing the attacker need is a short recording of ``Ok Google'' in the victim's voice, but the harm can be huge.


\subsection{Liveness Detection}
Voice spoofing attacks drastically degrade the performance of standard voice authentication systems by increasing false acceptance rates~\cite{wang2011channel, ergunay2015vulnerability}, leading to severe security and privacy issues. Fortunately, researchers have done extensive research on defending these attacks and building spoof-proof voice authentication systems.




\input{Chapters/MoVo/table}

As mentioned in Section~\ref{sec:spoof}, the threat of impersonation attack is much less than that of the other three attacks, so impersonation attack is not a research focus. For replay attack, speech synthesis, and voice conversion, researchers have noticed that they have one thing in common -- the attacking sound is played by an electronic speaker\footnote{In this and many other papers, attackers must play the attacking sound near the targeted smartphone. We do not consider the scenario where sound files are directly injected. Because if attackers can inject sounds to the system, the phone is already hacked. So there is no need to go through the voice authentication procedure anymore.} rather than spoken by a real person. Therefore, if the authentication system can distinguish whether the sound comes from a live person or an electronic device, it would be immune from those voice spoofing attacks.



Existing liveness detection methods can be classified into two groups: detecting human-related characteristics, or detecting device-related characteristics. 

As listed in Table~\ref{tab:liveness}, there have been many researches on detecting human-related characteristics.  
Girija Chetty and Michael Wagner~\cite{chetty2004automated} use cameras to detect lip movements to detect liveness. However, their work requires the camera access and inherits the shortcomings of face authentication systems. Similarly, Meng et al.~\cite{meng2018wivo} tries to detect mouth movement, but from channel state information from WiFi signals. Their approach requires antenna pairs and the antennas are placed very close to human (20cm), which is not practical in reality.
Poss et al.~\cite{poss2008biometric} use neural tree networks to determine unique aspects of utterances and hidden Markov models to classify those features. However, their work requires high computing power and long processing time. 
Wei Shang and Maryhelen Stevenson~\cite{shang2010score} detect liveness by testing whether an incoming recording shares the same originating utterance as any of previously-stored recordings. However, the performance of their work is largely based on the previously-stored recordings. 
Aley-Raz et al.~\cite{aley2013device} integrate intra-session voice variation to Nuance VocalPassword~\cite{onlinenuance} for liveness detection, but they require the user to cumbersomely repeat prompted sentences.
Zhang et al.~\cite{zhang2016voicelive} detect liveness by measuring the time-difference-of-arrival changes of a sequence of phoneme sounds using the two microphones of the phone, which requires at least two high-quality microphones in one smartphone. They also propose another work~\cite{zhang2017hearing} to detect users' articulatory gestures when speaking. However, their work requires high quality microphones again and needs a longer computation time.
Last but not least, Feng et al.~\cite{feng2017continuous}  utilizes the instantaneous consistency of the entire signal from the accelerometer and the microphone for liveness detection. Their work is the most closely related work to ours. However,  their work requires the user to wear extra accelerometers on the facial, throat, or sternum areas. Moreover, the accelerometer used in their work requires a very high sampling rate (11,000 Hz), which cannot be supported by current smartphones. In this work, we are only using a 400 Hz sampling rate for the accelerometer and the gyroscope.

The aforementioned researchers detects the liveness of a user directly, but we can also detect the liveness from the reverse side: detecting the presence of electronic devices. For example, Jes{\'u}s Villalba and Eduardo Lleida~\cite{villalba2011detecting}  detect noises and spectrum changes caused by far-field microphone and loudspeakers. Wang et al.~\cite{wang2011channel} detect channel pattern noise caused by microphone and loudspeakers to identify replay attackers. However, they can only deal with attackers who use low-quality microphones to record the legitimate user's voices or record the voice at a long distance. More recently, Chen et al.~\cite{chen2017you} detects the magnetic field emitted from loudspeakers to identify attacks, but their work requires the user to move the smartphone with the predefined trajectory around the sound source.


In conclusion, liveness detection methods either detect the presence of human beings or the presence of electronic devices. Existing work has at least one of the following shortcomings: 1) requiring special or extra devices; 2) requiring cumbersome user interaction; 3) requiring high computing power or long processing time; 4) limited ability in defending against spoofing attacks. Therefore, building a spoof-proof voice authentication system is still an open problem.



\begin{figure}[!h]
	\centering
	\begin{subfigure}[b]{0.15\textwidth}
		\centering
		\includegraphics[height=1.8in]{standing}
		\caption{Standing}
	\end{subfigure}%
	~~~\qquad
	\begin{subfigure}[b]{0.15\textwidth}
		\centering
		\includegraphics[height=1.8in]{walking}
		\caption{Walking}
	\end{subfigure}
	~~~\qquad
	\begin{subfigure}[b]{0.15\textwidth}
		\centering
		\includegraphics[height=1.5in]{sitting}
		\caption{Sitting}\label{fig:usec}
	\end{subfigure}
	\caption[Authentication Scenario of {\shortname}]{Authentication scenario of {\shortname}: holding the smartphone in contact with the throat while authenticating. In this way, the smartphone captures the body-borne voice vibrations through accelerometers and gyroscopes.}
	\label{fig:use}
\end{figure}


\subsection{Overview of {\shortname}}

In this thesis, we propose {\shortname}, a spoof-proof voice authentication system that using \underline{mo}tion sensors (accelerometers and gyroscopes) to measure \underline{vo}ice.


As shown in Fig.~\ref{fig:use}, the user places the smartphone horizontally and makes sure the phone is in close contact with his throat. Then the embedded motion sensors inside the phone captures the conductive vibrations from vocal organs to the throat, and to the smartphone. Afterwards, the collected motion sensor data will be used for user authentication.


The intuition behind {\shortname} is the fact that human voice is essentially vibrations, so it can be recorded by motion sensors ~\cite{hopkin2003getting,o2009sonic,michalevsky2014gyrophone}.  Such motion-sensor data can be regarded as downsampled microphone data, so it has potentials to be used for voice authentication too. 
%
Moreover, since human body is a nonlinear medium similar to water~\cite{kim2014sound}, sounds go through the body will be affected by acoustic attenuation~\cite{szabo1994time} and self demodulation~\cite{berktay1965possible}. Such effects are human-only effects in that electronic devices are not water-like medium and have totally different acoustic properties. Therefore, using motion data for authentication can effectively differentiate live people from electronic devices, so that the system is protected against various voice spoofing attacks.

In fact,  there have been some recent studies that show the possibility of acquiring acoustic signals by smartphones' motion sensors. Michalevsky et al.~\cite{michalevsky2014gyrophone} proposed \textit{Gyrophone} in 2014. To the best of our knowledge, they are the first to use smartphone gyroscopes as low-frequency microphones to listen to loudspeakers. Gyrophone can differentiate 11 digits\footnote{One, two, \ldots, nine and zero.} with 65\% accuracy based on a 10 people dataset.
%
One year later, Zhang et al.~\cite{zhang2015accelword} proposed \textit{AccelWord}, which utilizes accelerometers to classify hotwords such as ``Okay Google'' or ``Hi Galaxy'' over other short phrases with 85\% accuracy. AccelWord is also tested over 10 people.
%
In 2018, however, Anald and Saxena~\cite{anand2018speechless} reproduced the aforementioned works and overturned their conclusions. They argued that smartphone motion sensors can not be affected by the speech signals transmitted through the air, no matter the sound source is a loudspeaker or a live person. They reported that only when the speakers and the motion sensors sharing a surface,  the  conductive vibrations will affect motion sensors' readings. Consisting with this newest research, {\shortname} asks the user to press the phone on his throat so that the body-borne vibrations are recorded, not the air-borne sounds.




In summary, compared to previous works, the {\shortname} system have the following features:
\begin{itemize}
	\item  \textbf{All-in-One}: {\shortname} is an integral method which handles user authentication and liveness detection at the same time.
	
	\item  \textbf{Applicable}: {\shortname} works with current-off-the-shelf commercial smartphones. It does not require any extra electronic device nor any special phone model, since the sensors being used (motion sensors) are embedded on almost every smartphones.
	
	\item \textbf{Easy}: Except for pressing the smartphone on the userâ€™s throat, {\shortname} does not ask users to do extra movements other than an ordinary speaking behavior.  
	
	\item \textbf{Improved Robust}: General voice authentication systems are sensitive to the surrounding noises and their performance will degrade a lot in noisy environments. {\shortname}, however, will not be affected. This is because smartphone's motion sensors measure the conductive vibrations and the  affection from air-borne sounds is very limited~\cite{anand2018speechless}.

	\item \textbf{Expandable}: MoVo currently is a  text-dependent voice authentication systems that detects certain hotwords. However, it can be expanded to a text-independent system since it is syllable-based (will be elaborated in Section~\ref{sec:system}).
	
\end{itemize}